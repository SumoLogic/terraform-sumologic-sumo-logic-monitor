{
  "name": "Nginx Ingress",
  "description": "Folder for Nginx Ingress Monitors",
  "type": "MonitorsLibraryFolderExport",
  "children": [
    {
      "name": "Nginx Ingress - Access from Highly Malicious Sources",
      "description": "This alert fires when an Nginx Ingress server is accessed from highly malicious IP addresses.",
      "type": "MonitorsLibraryMonitorExport",
      "monitorType": "Logs",
      "evaluationDelay": "0m",
      "alertName": null,
      "runAs": null,
      "notificationGroupFields": [],
      "queries": [
        {
          "rowId": "A",
          "query": "webserver_system=nginx_ingress webserver_farm=* namespace=* deployment=* pod=*\n| json auto maxdepth 1 nodrop\n| if (isEmpty(log), _raw, log) as nginx_log_message\n| if (isEmpty(pod),_sourceHost,pod) as Server\n| parse regex field=nginx_log_message \"(?<ClientIp>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\"\n| where ClientIp != \"0.0.0.0\" and ClientIp != \"127.0.0.1\"\n| count as ip_count by ClientIp, Server\n| threatlookup singleIndicator ClientIp\n| where (_threatlookup.type=\"ipv4-addr:value\" or _threatlookup.type=\"ipv6-addr:value\") and !isNull(_threatlookup.confidence)\n| if (_threatlookup.confidence >= 85, \"high\", if (_threatlookup.confidence >= 50, \"medium\", if (_threatlookup.confidence >= 15, \"low\", if (_threatlookup.confidence >= 0, \"unverified\", \"Unknown\")))) as malicious_confidence\n| if (isEmpty(_threatlookup.actors), \"Unassigned\", _threatlookup.actors) as Actor\n| where malicious_confidence=\"high\"\n| sum (ip_count) as ThreatCount by ClientIp, Server, malicious_confidence, Actor"
        }
      ],
      "triggers": [
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "Critical",
          "resolutionWindow": null,
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "GreaterThan",
          "field": null,
          "occurrenceType": "ResultCount",
          "triggerSource": "AllResults",
          "minDataPoints": null
        },
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "ResolvedCritical",
          "resolutionWindow": null,
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "LessThanOrEqual",
          "field": null,
          "occurrenceType": "ResultCount",
          "triggerSource": "AllResults",
          "minDataPoints": null
        }
      ],
      "timeZone": null,
      "notifications": [],
      "isDisabled": true,
      "groupNotifications": true,
      "playbook": "",
      "sloId": null,
      "monitorTemplateId": null,
      "tags": null,
      "automatedPlaybookIds": []
    },
    {
      "name": "Nginx Ingress - High Client (HTTP 4xx) Error Rate",
      "description": "This alert fires when there are too many HTTP requests (>5%) with a response status of 4xx.",
      "type": "MonitorsLibraryMonitorExport",
      "monitorType": "Logs",
      "evaluationDelay": "0m",
      "runAs": null,
      "notificationGroupFields": [],
      "queries": [
        {
          "rowId": "A",
          "query": "webserver_system=nginx_ingress webserver_farm=* namespace=* deployment=* pod=*\n| json auto maxdepth 1 nodrop\n| if (isEmpty(log), _raw, log) as nginx_log_message\n| if (isEmpty(pod),_sourceHost,pod) as Server\n| parse regex field=nginx_log_message \"(?<Method>[A-Z]+)\\s(?<URL>\\S+)\\sHTTP/[\\d\\.]+\\\"\\s(?<StatusCode>\\d+)\\s(?<Size>[\\d-]+)\\s\\\"(?<Referrer>.*?)\\\"\\s\\\"(?<UserAgent>.+?)\\\".*\"\n| if (StatusCode matches \"4*\", 1, 0) as ServerError\n| sum(ServerError) as ServerErrors, count as TotalRequests by Server\n| (ServerErrors/TotalRequests) * 100 as ErrorPercentage\n| where ErrorPercentage > 5\n| fields Server, ErrorPercentage, ServerErrors, TotalRequests"
        }
      ],
      "triggers": [
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "Critical",
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "GreaterThan",
          "field": "",
          "occurrenceType": "ResultCount",
          "triggerSource": "AllResults"
        },
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "ResolvedCritical",
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "LessThanOrEqual",
          "field": "",
          "occurrenceType": "ResultCount",
          "triggerSource": "AllResults"
        }
      ],
      "notifications": [],
      "isDisabled": true,
      "groupNotifications": true,
      "playbook": ""
    },
    {
      "name": "Nginx Ingress - High Server (HTTP 5xx) Error Rate",
      "description": "This alert fires when there are too many HTTP requests (>5%) with a response status of 5xx.",
      "type": "MonitorsLibraryMonitorExport",
      "monitorType": "Logs",
      "evaluationDelay": "0m",
      "runAs": null,
      "notificationGroupFields": [],
      "queries": [
        {
          "rowId": "A",
          "query": "webserver_system=nginx_ingress webserver_farm=* namespace=* deployment=* pod=*\n| json auto maxdepth 1 nodrop\n| if (isEmpty(log), _raw, log) as nginx_log_message\n| if (isEmpty(pod),_sourceHost,pod) as Server\n| parse regex field=nginx_log_message \"(?<Method>[A-Z]+)\\s(?<URL>\\S+)\\sHTTP/[\\d\\.]+\\\"\\s(?<StatusCode>\\d+)\\s(?<Size>[\\d-]+)\\s\\\"(?<Referrer>.*?)\\\"\\s\\\"(?<UserAgent>.+?)\\\".*\"\n| if (StatusCode matches \"5*\", 1, 0) as ServerError\n| sum(ServerError) as ServerErrors, count as TotalRequests by Server\n| (ServerErrors/TotalRequests) * 100 as ErrorPercentage\n| where ErrorPercentage > 5\n| fields Server, ErrorPercentage, ServerErrors, TotalRequests"
        }
      ],
      "triggers": [
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "Critical",
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "GreaterThan",
          "field": "",
          "occurrenceType": "ResultCount",
          "triggerSource": "AllResults"
        },
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "ResolvedCritical",
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "LessThanOrEqual",
          "field": "",
          "occurrenceType": "ResultCount",
          "triggerSource": "AllResults"
        }
      ],
      "notifications": [],
      "isDisabled": true,
      "groupNotifications": true,
      "playbook": ""
    },
    {
      "name": "Nginx Ingress - Critical Error Messages",
      "description": "This alert fires when we detect critical error messages for a given Nginx Ingress server.",
      "type": "MonitorsLibraryMonitorExport",
      "monitorType": "Logs",
      "evaluationDelay": "0m",
      "runAs": null,
      "notificationGroupFields": [],
      "queries": [
        {
          "rowId": "A",
          "query": "webserver_system=nginx_ingress webserver_farm=* namespace=* deployment=* pod=*\n| json auto maxdepth 1 nodrop\n| if (isEmpty(log), _raw, log) as nginx_log_message\n| if (isEmpty(pod),_sourceHost,pod) as Server\n| parse regex field=nginx_log_message \"\\s\\[(?<LogLevel>\\S+)\\]\\s\\d+#\\d+:\\s(?:\\*\\d+\\s|)(?<Message>[A-Za-z][^,]+)(?:,|$)\"\n| where LogLevel in (\"emerg\", \"alert\", \"crit\")\n| formatDate(_messageTime, \"MMM/dd/yyyy HH:mm:ss:SSS Z\") as MessageDate\n| count by MessageDate, Server, LogLevel, Message\n| fields MessageDate, Server, LogLevel, Message"
        }
      ],
      "triggers": [
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "Critical",
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "GreaterThan",
          "field": "",
          "occurrenceType": "ResultCount",
          "triggerSource": "AllResults"
        },
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "ResolvedCritical",
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "LessThanOrEqual",
          "field": "",
          "occurrenceType": "ResultCount",
          "triggerSource": "AllResults"
        }
      ],
      "notifications": [],
      "isDisabled": true,
      "groupNotifications": true,
      "playbook": ""
    },
    {
      "name": "Nginx Ingress - Dropped Connections",
      "description": "This alert fires when we detect dropped connections for a given Nginx Ingress server.",
      "type": "MonitorsLibraryMonitorExport",
      "monitorType": "Metrics",
      "evaluationDelay": "0m",
      "runAs": null,
      "notificationGroupFields": [],
      "queries": [
        {
          "rowId": "A",
          "query": "metric = nginx_ingress_nginx_connections_handled webserver_system=nginx_ingress webserver_farm=* namespace=* deployment=* pod=* | sum by webserver_farm, deployment, namespace, pod"
        },
        {
          "rowId": "B",
          "query": "metric = nginx_ingress_nginx_connections_accepted webserver_system=nginx_ingress webserver_farm=* namespace=* deployment=* pod=* | sum by webserver_farm, deployment, namespace, pod"
        },
        {
          "rowId": "C",
          "query": "#B - #A along webserver_farm, deployment, namespace, pod"
        }
      ],
      "triggers": [
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "Critical",
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "GreaterThan",
          "field": null,
          "occurrenceType": "Always",
          "triggerSource": "AnyTimeSeries"
        },
        {
          "detectionMethod": "StaticCondition",
          "triggerType": "ResolvedCritical",
          "timeRange": "-5m",
          "threshold": 0,
          "thresholdType": "LessThanOrEqual",
          "field": null,
          "occurrenceType": "Always",
          "triggerSource": "AnyTimeSeries"
        }
      ],
      "notifications": [],
      "isDisabled": true,
      "groupNotifications": true,
      "playbook": ""
    }
  ]
}